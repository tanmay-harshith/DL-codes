{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], d_loss: 0.6484, g_loss: 0.8979\n",
      "Epoch [2/100], d_loss: 0.6505, g_loss: 0.8792\n",
      "Epoch [3/100], d_loss: 0.3078, g_loss: 1.7344\n",
      "Epoch [4/100], d_loss: 1.6267, g_loss: 5.4260\n",
      "Epoch [5/100], d_loss: 2.4967, g_loss: 6.6390\n",
      "Epoch [6/100], d_loss: 0.9743, g_loss: 4.0700\n",
      "Epoch [7/100], d_loss: 0.8005, g_loss: 4.4599\n",
      "Epoch [8/100], d_loss: 0.4709, g_loss: 4.1452\n",
      "Epoch [9/100], d_loss: 0.6142, g_loss: 2.9270\n",
      "Epoch [10/100], d_loss: 1.2663, g_loss: 5.0968\n",
      "Epoch [11/100], d_loss: 1.3170, g_loss: 7.1575\n",
      "Epoch [12/100], d_loss: 0.9928, g_loss: 5.5303\n",
      "Epoch [13/100], d_loss: 0.2240, g_loss: 5.6604\n",
      "Epoch [14/100], d_loss: 0.2756, g_loss: 4.1993\n",
      "Epoch [15/100], d_loss: 0.3625, g_loss: 7.5386\n",
      "Epoch [16/100], d_loss: 0.2371, g_loss: 10.4786\n",
      "Epoch [17/100], d_loss: 0.6218, g_loss: 10.0314\n",
      "Epoch [18/100], d_loss: 0.4184, g_loss: 7.5939\n",
      "Epoch [19/100], d_loss: 0.1670, g_loss: 7.8173\n",
      "Epoch [20/100], d_loss: 0.3078, g_loss: 16.6740\n",
      "Epoch [21/100], d_loss: 0.4786, g_loss: 25.3342\n",
      "Epoch [22/100], d_loss: 0.1829, g_loss: 18.1764\n",
      "Epoch [23/100], d_loss: 0.3622, g_loss: 10.1349\n",
      "Epoch [24/100], d_loss: 0.2118, g_loss: 7.1302\n",
      "Epoch [25/100], d_loss: 0.0212, g_loss: 8.8922\n",
      "Epoch [26/100], d_loss: 0.0457, g_loss: 11.9032\n",
      "Epoch [27/100], d_loss: 0.1664, g_loss: 16.8521\n",
      "Epoch [28/100], d_loss: 0.0797, g_loss: 18.7757\n",
      "Epoch [29/100], d_loss: 0.2500, g_loss: 28.0442\n",
      "Epoch [30/100], d_loss: 0.3291, g_loss: 34.5415\n",
      "Epoch [31/100], d_loss: 0.0584, g_loss: 20.6126\n",
      "Epoch [32/100], d_loss: 0.3018, g_loss: 13.9190\n",
      "Epoch [33/100], d_loss: 0.1034, g_loss: 12.5728\n",
      "Epoch [34/100], d_loss: 0.1806, g_loss: 24.6011\n",
      "Epoch [35/100], d_loss: 0.1040, g_loss: 21.3337\n",
      "Epoch [36/100], d_loss: 0.1638, g_loss: 24.1867\n",
      "Epoch [37/100], d_loss: 0.0740, g_loss: 45.9879\n",
      "Epoch [38/100], d_loss: 0.0417, g_loss: 47.0800\n",
      "Epoch [39/100], d_loss: 0.0477, g_loss: 26.0363\n",
      "Epoch [40/100], d_loss: 0.1443, g_loss: 15.7886\n",
      "Epoch [41/100], d_loss: 0.1405, g_loss: 6.8917\n",
      "Epoch [42/100], d_loss: 0.0176, g_loss: 9.2456\n",
      "Epoch [43/100], d_loss: 0.0129, g_loss: 12.5589\n",
      "Epoch [44/100], d_loss: 0.0243, g_loss: 12.9343\n",
      "Epoch [45/100], d_loss: 0.0341, g_loss: 16.8990\n",
      "Epoch [46/100], d_loss: 0.3031, g_loss: 6.4280\n",
      "Epoch [47/100], d_loss: 0.0432, g_loss: 6.8839\n",
      "Epoch [48/100], d_loss: 0.0921, g_loss: 9.0569\n",
      "Epoch [49/100], d_loss: 0.1075, g_loss: 12.5309\n",
      "Epoch [50/100], d_loss: 0.2521, g_loss: 8.8190\n",
      "Epoch [51/100], d_loss: 0.3632, g_loss: 11.7233\n",
      "Epoch [52/100], d_loss: 0.7347, g_loss: 15.1417\n",
      "Epoch [53/100], d_loss: 0.0940, g_loss: 7.2936\n",
      "Epoch [54/100], d_loss: 0.0957, g_loss: 11.8493\n",
      "Epoch [55/100], d_loss: 0.2518, g_loss: 6.2579\n",
      "Epoch [56/100], d_loss: 0.1111, g_loss: 5.7736\n",
      "Epoch [57/100], d_loss: 0.6007, g_loss: 5.6994\n",
      "Epoch [58/100], d_loss: 0.2171, g_loss: 5.3123\n",
      "Epoch [59/100], d_loss: 0.0837, g_loss: 7.6686\n",
      "Epoch [60/100], d_loss: 0.0242, g_loss: 6.0918\n",
      "Epoch [61/100], d_loss: 0.0481, g_loss: 7.6273\n",
      "Epoch [62/100], d_loss: 1.0407, g_loss: 5.1596\n",
      "Epoch [63/100], d_loss: 0.0304, g_loss: 5.1800\n",
      "Epoch [64/100], d_loss: 0.0477, g_loss: 5.0390\n",
      "Epoch [65/100], d_loss: 0.1100, g_loss: 6.0889\n",
      "Epoch [66/100], d_loss: 0.0521, g_loss: 4.9293\n",
      "Epoch [67/100], d_loss: 0.5304, g_loss: 4.9828\n",
      "Epoch [68/100], d_loss: 0.1624, g_loss: 3.8865\n",
      "Epoch [69/100], d_loss: 0.0908, g_loss: 7.0202\n",
      "Epoch [70/100], d_loss: 0.1432, g_loss: 5.8889\n",
      "Epoch [71/100], d_loss: 0.2815, g_loss: 6.5463\n",
      "Epoch [72/100], d_loss: 0.4415, g_loss: 7.7342\n",
      "Epoch [73/100], d_loss: 0.1514, g_loss: 4.5408\n",
      "Epoch [74/100], d_loss: 0.8625, g_loss: 5.1446\n",
      "Epoch [75/100], d_loss: 0.2456, g_loss: 5.0075\n",
      "Epoch [76/100], d_loss: 0.1653, g_loss: 6.1114\n",
      "Epoch [77/100], d_loss: 0.2691, g_loss: 4.9027\n",
      "Epoch [78/100], d_loss: 0.5617, g_loss: 3.8598\n",
      "Epoch [79/100], d_loss: 0.5851, g_loss: 3.2652\n",
      "Epoch [80/100], d_loss: 0.7742, g_loss: 4.7107\n",
      "Epoch [81/100], d_loss: 0.2022, g_loss: 6.1415\n",
      "Epoch [82/100], d_loss: 1.1710, g_loss: 4.5733\n",
      "Epoch [83/100], d_loss: 0.2203, g_loss: 4.5907\n",
      "Epoch [84/100], d_loss: 0.0878, g_loss: 3.6283\n",
      "Epoch [85/100], d_loss: 0.1749, g_loss: 2.8475\n",
      "Epoch [86/100], d_loss: 0.1908, g_loss: 3.1741\n",
      "Epoch [87/100], d_loss: 0.2755, g_loss: 3.4395\n",
      "Epoch [88/100], d_loss: 0.1535, g_loss: 2.8003\n",
      "Epoch [89/100], d_loss: 0.4853, g_loss: 2.8979\n",
      "Epoch [90/100], d_loss: 0.5270, g_loss: 2.5893\n",
      "Epoch [91/100], d_loss: 0.4108, g_loss: 2.7557\n",
      "Epoch [92/100], d_loss: 0.2179, g_loss: 2.9334\n",
      "Epoch [93/100], d_loss: 0.9098, g_loss: 3.0310\n",
      "Epoch [94/100], d_loss: 0.4525, g_loss: 3.9995\n",
      "Epoch [95/100], d_loss: 0.1968, g_loss: 4.5902\n",
      "Epoch [96/100], d_loss: 1.2171, g_loss: 4.9078\n",
      "Epoch [97/100], d_loss: 0.1412, g_loss: 3.9400\n",
      "Epoch [98/100], d_loss: 0.8438, g_loss: 3.5544\n",
      "Epoch [99/100], d_loss: 0.0405, g_loss: 4.1623\n",
      "Epoch [100/100], d_loss: 0.1455, g_loss: 3.6665\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the Generator network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, text_embed_dim, img_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(noise_dim + text_embed_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, img_size * img_size * 3)  # 3 for RGB channels\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, noise, text_embedding):\n",
    "        x = torch.cat((noise, text_embedding), dim=1)  # Concatenate noise and text embedding\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.tanh(self.fc3(x))  # Output between -1 and 1 for images\n",
    "        x = x.view(-1, 3, img_size, img_size)  # Reshape to image dimensions\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the Discriminator network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_size, text_embed_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(img_size * img_size * 3 + text_embed_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, img, text_embedding):\n",
    "        img = img.view(img.size(0), -1)  # Flatten image\n",
    "        x = torch.cat((img, text_embedding), dim=1)  # Concatenate image and text embedding\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))  # Output between 0 and 1\n",
    "        return x\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "noise_dim = 100\n",
    "text_embed_dim = 128  # Text embedding dimension\n",
    "img_size = 64  # Image size (64x64)\n",
    "batch_size = 32\n",
    "lr = 0.0002\n",
    "num_epochs = 100\n",
    "\n",
    "# Create generator and discriminator\n",
    "G = Generator(noise_dim, text_embed_dim, img_size).to(device)\n",
    "D = Discriminator(img_size, text_embed_dim).to(device)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(G.parameters(), lr=lr)\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=lr)\n",
    "\n",
    "# Function to generate random noise and text embeddings\n",
    "def generate_noise(batch_size, noise_dim):\n",
    "    return torch.randn(batch_size, noise_dim).to(device)\n",
    "\n",
    "def generate_text_embeddings(batch_size, text_embed_dim):\n",
    "    return torch.randn(batch_size, text_embed_dim).to(device)  # Fake text embeddings\n",
    "\n",
    "\n",
    "# Training the GAN\n",
    "for epoch in range(num_epochs):\n",
    "    for _ in range(batch_size):  # Adjusted to mimic mini-batches\n",
    "        # Generate fake and real data\n",
    "        real_imgs = torch.randn(batch_size, 3, img_size, img_size).to(device)  # Simulated real images\n",
    "        real_text_embeddings = generate_text_embeddings(batch_size, text_embed_dim)\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Generate fake images\n",
    "        noise = generate_noise(batch_size, noise_dim)\n",
    "        fake_text_embeddings = generate_text_embeddings(batch_size, text_embed_dim)\n",
    "        fake_imgs = G(noise, fake_text_embeddings)\n",
    "\n",
    "        # Train Discriminator\n",
    "        outputs_real = D(real_imgs, real_text_embeddings)\n",
    "        d_loss_real = criterion(outputs_real, real_labels)\n",
    "\n",
    "        outputs_fake = D(fake_imgs.detach(), fake_text_embeddings)\n",
    "        d_loss_fake = criterion(outputs_fake, fake_labels)\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        optimizer_D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train Generator\n",
    "        outputs_fake = D(fake_imgs, fake_text_embeddings)\n",
    "        g_loss = criterion(outputs_fake, real_labels)  # Generator tries to fool the discriminator\n",
    "        optimizer_G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}')\n",
    "\n",
    "    # Save generated images every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        save_image(fake_imgs.data[:25], f'generated_images_{epoch + 1}.png', nrow=5, normalize=True)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(G.state_dict(), 'generator.pth')\n",
    "torch.save(D.state_dict(), 'discriminator.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
