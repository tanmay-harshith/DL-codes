{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Dense, Conv2D, Flatten, concatenate\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, concatenate\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Step 1: Define the Multi-Input, Multi-Output Model\n",
    "def build_model(hp):\n",
    "    # Hyperparameters for tuning\n",
    "    units_1 = hp.Int('units_1', min_value=32, max_value=128, step=32)\n",
    "    units_2 = hp.Int('units_2', min_value=32, max_value=128, step=32)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    # Input 1: Feature vector for regression task\n",
    "    input_1 = Input(shape=(10,), name=\"input_1\")  # Feature vector of length 10\n",
    "    x1 = Dense(units_1, activation='relu')(input_1)\n",
    "    x1 = Dense(units_2, activation='relu')(x1)\n",
    "\n",
    "    # Input 2: Image data for classification task\n",
    "    input_2 = Input(shape=(64, 64, 3), name=\"input_2\")  # Example 64x64 RGB image\n",
    "    x2 = Conv2D(32, (3, 3), activation='relu')(input_2)\n",
    "    x2 = Conv2D(64, (3, 3), activation='relu')(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "\n",
    "    # Combine both inputs\n",
    "    combined = concatenate([x1, x2])\n",
    "\n",
    "    # Output 1: Regression output\n",
    "    output_1 = Dense(1, name=\"output_1\")(combined)\n",
    "\n",
    "    # Output 2: Classification output\n",
    "    output_2 = Dense(10, activation='softmax', name=\"output_2\")(combined)  # 10-class classification\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=[input_1, input_2], outputs=[output_1, output_2])\n",
    "\n",
    "    # Compile the model with the tunable learning rate\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss={'output_1': 'mse', 'output_2': 'categorical_crossentropy'},\n",
    "        metrics={'output_1': 'mae', 'output_2': 'accuracy'}\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Step 2: Set up Hyperparameter Tuning with Keras Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,  # Number of different hyperparameter sets to try\n",
    "    executions_per_trial=2,  # Number of models built for each set of hyperparameters\n",
    "    directory='my_dir',\n",
    "    project_name='multi_input_multi_output_tuning'\n",
    ")\n",
    "\n",
    "# Generate random data for illustration purposes\n",
    "x1_data = np.random.rand(1000, 10)  # Random feature vectors\n",
    "x2_data = np.random.rand(1000, 64, 64, 3)  # Random image data\n",
    "y1_data = np.random.rand(1000, 1)  # Random regression targets\n",
    "y2_data = np.random.randint(0, 10, (1000, 1))  # Random classification targets (10 classes)\n",
    "\n",
    "# One-hot encoding of the classification labels\n",
    "y2_data = tf.keras.utils.to_categorical(y2_data, num_classes=10)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "x1_train, x1_val = x1_data[:800], x1_data[800:]\n",
    "x2_train, x2_val = x2_data[:800], x2_data[800:]\n",
    "y1_train, y1_val = y1_data[:800], y1_data[800:]\n",
    "y2_train, y2_val = y2_data[:800], y2_data[800:]\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuner.search(\n",
    "    [x1_train, x2_train], \n",
    "    [y1_train, y2_train],\n",
    "    validation_data=([x1_val, x2_val], [y1_val, y2_val]),\n",
    "    epochs=5, \n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Print a summary of the best model\n",
    "best_model.summary()\n",
    "\n",
    "# Step 3: Train the best model on the full dataset\n",
    "best_model.fit(\n",
    "    [x1_train, x2_train], \n",
    "    [y1_train, y2_train], \n",
    "    epochs=5, \n",
    "    batch_size=32\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
